Below, I provide a **theorem** for **constraint satisfaction in MAPPO-Lagrangian (MAPPO-L)** and derive a **Chebyshev-based bound** for constraint violation that explicitly accounts for **critic approximation errors**. This combines theoretical guarantees with practical probabilistic bounds.

---

## **Theorem: Constraint Satisfaction in MAPPO-L**

### **Assumptions**
1. **Policy Optimization**:
   - The policy \( \pi \) is optimized using the MAPPO-L algorithm, which combines proximal policy optimization (PPO) with Lagrangian relaxation to handle constraints.
   - The Lagrangian multiplier \( \lambda \) is updated using dual ascent.

2. **Critic Approximation**:
   - The critic \( \hat{V}^\pi(s) \) approximates the true value function \( V^\pi(s) \) with a bounded error:
     \[
     |V^\pi(s) - \hat{V}^\pi(s)| \leq \epsilon_\text{critic},
     \]
     where \( \epsilon_\text{critic} \) is the maximum critic approximation error.

3. **Constraint Violation**:
   - The constraint violation \( C_t \) at time \( t \) has a bounded mean \( \mu_t \) and variance \( \sigma_t^2 \):
     \[
     \mathbb{E}[C_t] = \mu_t, \quad \text{Var}(C_t) = \sigma_t^2.
     \]

4. **Finite Horizon**:
   - The time horizon \( T \) is finite.

---

### **Theorem Statement**
Under the above assumptions, the MAPPO-L algorithm ensures that the **cumulative constraint violation** \( S_T = \sum_{t=1}^T C_t \) satisfies the following probabilistic guarantee:

\[
P\left( S_T \geq \epsilon \right) \leq \frac{\sum_{t=1}^T (\sigma_t^2 + \sigma_\epsilon^2)}{(\epsilon - \sum_{t=1}^T (\mu_t + \mu_\epsilon))^2},
\]

where:
- \( \mu_\epsilon = \mathbb{E}[\epsilon_t] \) is the mean critic approximation error,
- \( \sigma_\epsilon^2 = \text{Var}(\epsilon_t) \) is the variance of the critic approximation error,
- \( \epsilon > \sum_{t=1}^T (\mu_t + \mu_\epsilon) \) is the constraint violation threshold.

---

### **Proof Sketch**
1. **Cumulative Constraint Violation**:
   - The cumulative constraint violation \( S_T = \sum_{t=1}^T C_t \) is affected by the critic approximation errors \( \epsilon_t \).

2. **Revised Mean and Variance**:
   - The expected value of \( S_T \) is:
     \[
     \mathbb{E}[S_T] = \sum_{t=1}^T (\mu_t + \mu_\epsilon).
     \]
   - The variance of \( S_T \) is:
     \[
     \text{Var}(S_T) = \sum_{t=1}^T (\sigma_t^2 + \sigma_\epsilon^2).
     \]

3. **Chebyshev's Inequality**:
   - Applying Chebyshev's inequality to \( S_T \):
     \[
     P\left( |S_T - \mathbb{E}[S_T]| \geq k \cdot \sqrt{\text{Var}(S_T)} \right) \leq \frac{1}{k^2},
     \]
     where \( k > 0 \).

4. **Constraint Violation Bound**:
   - Setting \( k = \frac{\epsilon - \mathbb{E}[S_T]}{\sqrt{\text{Var}(S_T)}} \), we obtain:
     \[
     P\left( S_T \geq \epsilon \right) \leq \frac{\text{Var}(S_T)}{(\epsilon - \mathbb{E}[S_T])^2}.
     \]

5. **Substitute Mean and Variance**:
   - Substituting \( \mathbb{E}[S_T] \) and \( \text{Var}(S_T) \) into the bound completes the proof.

---

## **Chebyshev-Based Bound for Constraint Violation**

### **Bound Derivation**
The probability that the cumulative constraint violation \( S_T \) exceeds a threshold \( \epsilon \) is bounded by:

\[
P\left( S_T \geq \epsilon \right) \leq \frac{\sum_{t=1}^T (\sigma_t^2 + \sigma_\epsilon^2)}{(\epsilon - \sum_{t=1}^T (\mu_t + \mu_\epsilon))^2}.
\]

---

### **Interpretation**
- **Critic Error Contribution**:
  - The critic approximation error increases both the mean \( \mathbb{E}[S_T] \) and variance \( \text{Var}(S_T) \) of the cumulative constraint violation, leading to a looser bound.
- **Finite Horizon Effects**:
  - For small \( T \), the bound may be loose due to limited averaging. For large \( T \), the bound becomes tighter.
- **Threshold \( \epsilon \)**:
  - The bound becomes tighter as \( \epsilon \) increases relative to the cumulative mean \( \mathbb{E}[S_T] \).

---

### **Example**
Suppose:
- \( T = 1000 \),
- \( \mu_t = 0.1 \) for all \( t \),
- \( \sigma_t^2 = 0.01 \) for all \( t \),
- \( \mu_\epsilon = 0.02 \) (constant critic bias),
- \( \sigma_\epsilon^2 = 0.001 \) (variance of critic error),
- \( \epsilon = 150 \).

Then:
- Cumulative mean: \( \mathbb{E}[S_T] = 1000 \times (0.1 + 0.02) = 120 \),
- Cumulative variance: \( \text{Var}(S_T) = 1000 \times (0.01 + 0.001) = 11 \).

The bound is:

\[
P\left( S_T \geq 150 \right) \leq \frac{11}{(150 - 120)^2} = \frac{11}{900} \approx 0.0122.
\]

Thus, the probability of exceeding \( \epsilon = 150 \) is at most 1.22%.

---

## **Discussion**
- **Tightness of the Bound**:
  - The Chebyshev bound is conservative. If more information about the distribution of \( C_t \) or \( \epsilon_t \) is available (e.g., Gaussian assumptions), tighter bounds (e.g., Hoeffding's inequality) can be derived.
- **Practical Implications**:
  - The bound provides a probabilistic guarantee for constraint satisfaction in MAPPO-L, accounting for critic approximation errors. It can be used to monitor and control constraint violations during training.

---

This theorem and bound provide a rigorous foundation for analyzing constraint satisfaction in MAPPO-L, explicitly incorporating critic approximation errors. If you have specific parameters or distributions in mind, I can refine the analysis further!
